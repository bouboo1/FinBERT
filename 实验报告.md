# <center>社会计算实验报告</center>

## 摘要
在这一部分，简要介绍论文的主题、主要研究内容以及实验结果的概览。

## 0  引言
在这一部分，介绍研究的背景和论文的主要目标和动机。

## 1 研究背景
FinBERT 论文专注于金融领域的情感分析，这是因为金融语言具有高度专业性，且相关的标记数据相对稀缺。尽管传统的情感分析模型在通用文本上表现良好，但在处理充满专业术语的金融文本时常常力不从心。随着金融文本量的日益增长，人工分析变得不切实际，这增加了对高效自动化分析工具的需求。在此背景下，FinBERT通过预训练的BERT模型，并在金融特定数据上进行微调，有效提升了对金融情感的分析准确性。<br>
基于FinBERT的成功，我们小组提出了将循环卷积神经网络（RCNN）与对抗训练相结合的新模型——FinBERT-RCNN。RCNN结合了循环神经网络(RNN)和卷积神经网络(CNN)的优势，优化了文本数据的深层次语义特征提取。通过引入对抗训练，我们旨在增强模型在面对金融文本中复杂情绪表达时的鲁棒性和泛化能力。


## 2 研究意义
本次研究通过创新地结合RCNN架构和对抗训练技术，显著优化了金融领域的情感分析工具。这种方法不仅提高了情感分析的精度，还增强了模型对金融市场情绪波动的适应性和敏感性。FinBERT-RCNN的开发标志着金融情感分析向更高精度和复杂情境适应性的进步，同时验证了混合神经网络模型处理特定领域问题的有效性。此外，对抗训练的引入为模型提供了额外的稳定性，使其在实际金融应用中更为可靠。<br>
本次研究为金融情感分析领域带来了新的研究方向和实际应用的可能性，有望更准确地预测市场对金融新闻的反应，从而为金融决策提供科学依据。通过这种先进的方法，我们能够更好地理解和利用大规模金融文本数据，为金融市场的稳定和发展做出贡献。


## 3 问题描述
在金融领域进行情感分析是一项具有挑战性的任务，这主要是因为两个原因：<br>
一是金融文本中使用了大量的专业术语和特有的语言表达，使得通用的情感分析模型难以有效适应；<br>
二是缺乏大量标注数据，使得训练精确的情感分析模型变得困难，因为标注金融文本片段需要耗费高昂的专业成本。<br>
针对这些问题，《FinBERT: Financial Sentiment Analysis with Pre-trained Language Models》一文提出的FinBERT模型通过使用预训练的语言模型来捕捉文本的上下文语义信息，显著提高了模型在金融文本情感分析任务中的表现。<br>
但是尽管FinBERT模型已在金融情感分析任务中取得显著成绩，但仍存在一些不足之处。<br>
首先，FinBERT模型虽能有效捕捉上下文语义信息，但在提取文本中的关键信息方面仍有待加强。<br>
其次，现有模型在抵御对抗性攻击方面的鲁棒性不足，容易受到微小扰动的影响，从而导致分类结果的不准确。<br>
基于这些现存问题，我们在FinBERT模型的基础上提出了FinBERT-RCNN-ATTACK模型，旨在通过结合RCNN结构提高关键信息的提取能力，并引入对抗训练来增强模型的抗干扰性。<br>
本研究的主要目标是验证通过进一步预训练和微调预训练语言模型，能否显著提高金融领域情感分析的准确性。我们的实验将集中在如何通过增强模型的关键信息提取能力和鲁棒性，来解决FinBERT在金融文本情感分析中遇到的挑战。


## 4 模型设计
在本研究中，我们引入了一种新的文本分析模型，FinBERT-RCNN-ATTACK，专门为金融领域的情感分析而设计。此模型结合了FinBERT预训练模型和循环卷积神经网络（RCNN）。FinBERT模型利用大规模的金融数据进行预训练，因此在处理金融相关任务时表现出更高的适应性。它通过嵌入捕获文本的语义特征，为分析提供支持。另一方面，RCNN通过其结构优化了上下文信息的捕获，能够有效提取文本中的关键特征。
此外，为了增强模型的鲁棒性和精确度，我们还引入了对抗性训练策略。通过使用损失函数的梯度来生成扰动，这些扰动被添加到文本嵌入中，随后模型在这些经过扰动的对抗样本上进行训练。该方法能够显著提升模型对抗新型攻击的能力。
整个模型的结构如图1所示，该结构有效地融合了FinBERT嵌入和RCNN技术，并通过对抗训练进一步增强了模型性能，特别适用于金融文本的深入分析和情感识别。

![Local Image](图片\图1模型结构.png "Local Image Title")<br><br>



 ### 4.1 FinBERT 模块
为了高效地从金融文本中提取语义特征，我们首先使用FinBERT预训练模型进行文本的嵌入处理，包括Token Embeddings、Segment Embeddings和Position Embeddings（如图2所示）。
![Local Image](图片\图2嵌入.png "Local Image Title")<br>
（1）Token Embeddings：该步骤将文本中的词转换为固定维度的向量，这是基本的语义信息编码。<br>
（2）Segment Embeddings：这些嵌入帮助模型区分同一句子对中的两个不同句子，增强了模型处理句子边界的能力。<br>
（3）Position Embeddings：通过这种嵌入，FinBERT能够识别输入序列中词的位置，有助于模型理解文本的顺序结构。

这三种向量的组合通过加和形式作为模型的输入，这样做能够综合保留原始文本的综合信息和情感倾向，为后续的任务提供支持。具体来说，组合后的向量\[ E_{\text{word}} = E_{\text{tok}} + E_{\text{seg}} + E_{\text{pos}} \]被用作输入，进一步通过多层Transformer结构进行特征提取，得到序列中各位置的特征向量 
\[ T_1, T_2, \ldots, T_n \]
这样的结构不仅提高了特征提取的精确性，还增强了模型对复杂金融语境的适应能力。<br><br>


### 4.2 RCNN 模块
情感分类的挑战主要在于从文本中提取具有决定性的信息。虽然FinBERT模型能够有效处理文本的上下文和语义信息，但在关键信息提取方面存在局限性。仅依靠FinBERT提取的特征进行情感分类可能导致分类性能未充分发挥。因此，结合FinBERT提取的语义特征和其他神经网络模型的特性可以有效提升整体的分类精度。

在本模型中，我们引入了RCNN来强化特征提取过程。RCNN通过将传统卷积神经网络中的卷积层替换为具有递归结构的循环卷积层，建立了一个深度前馈网络。如图3所示，循环卷积层能够分别从左到右及从右到左学习每个单词，从而捕捉字符及其上下文的全面信息。这些信息被输入到池化层，在池化层中通过max-pooling操作选取文本中最具代表性的关键特征。之后，特征通过全连接层进行处理，并最终通过softmax函数进行情感分类。
![Local Image](图片\图3循环卷积层结构.png "Local Image Title")<br>


这种结合了FinBERT和RCNN的模型不仅优化了特征的语义深度，也提高了情感分类任务的整体效果。<br><br>


### 4.3 对抗训练
为了增强文本分类模型的鲁棒性和泛化能力，提高分类准确性，本研究在文本表示模型生成的词向量中引入了对抗性扰动。对抗样本的核心特征在于，尽管扰动微小且不影响模型的基本分类性能，但足以对模型的鲁棒性进行测试。

根据文献[x]提出的方法，对抗扰动是通过使用损失函数的梯度来计算得到的，具体公式如下：

\[ r_{\text{adv}} = \arg \min \log p(y | x + r; \theta) \]
\[ \text{subject to} \ \|r\| \leq \epsilon \]

其中 \( p(y \mid x; \theta) \) 表示在给定输入 \( x \) 和模型参数 \( \theta \) 的情况下，预测标签 \( y \) 的概率；\( r \) 是加在输入上的扰动，且此扰动在 \( \epsilon \) 范围内被严格限制。目标是寻找能够最大化模型预测误差的最优扰动 \( r \)，通过在 \( x \) 附近线性化损失函数实现这一目标。通过此方法，对抗性扰动被添加到输入嵌入中，以在嵌入空间中构造新的对抗性文本实例。这种策略旨在通过暴露模型在极端情况下的表现，来提升模型在现实世界应用中的健壮性和可靠性。<br><br>
## 5 实验评价


### 5.1数据集介绍
数据集名称：Sentiment Analysis for Financial News
我们小组选取1个公开的英文数据集对提出的模型和其他现有模型进行实验，划分80%（3876条）作为训练数据，20%（970条）作为测试数据。该数据集包含从零售投资者视角出发的金融新闻标题的情感标注，用于研究和分析金融新闻对市场参与者情绪的影响，尤其关注新闻标题所蕴含的情绪倾向。通过对新闻标题的情感分析，可以帮助金融分析师和投资者更好地理解市场动态，预测市场趋势。
数据集包括两个字段：“情感”（Sentiment）和“新闻标题”（News Headline）。情感分类包括负面（negative）、中性（neutral）和正面（positive），这使得研究者可以直接利用这些数据进行情感分析，探索不同新闻标题背后的情感色彩。<br><br>


### 5.2 评估指标
实验使用精确率( Precision) 、召回率 ( Recall) 和F1 分数(F1-Score)作为衡量模型分类性能的标准，计算公式如下所示。

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

$$
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$


其中，TP( True Positive) 表示被正确预测的正例 。即 该数据的真实值为正例，预测值也为正例的情况；FP (False Positive)表示被错误预测的正例 。即该数据的 真实值为 反 例，但 被 错 误 预 测 成 了 正 例 的 情 况；FN (False Negative) 表示被错误预测的反例 。即该数据 的真实值为正例，但被错误预测成了反例的情况。<br><br>

### 5.3 实验环境
实验基于 PyTorch 框架，版本为 2.2.1，与 CUDA 11.8 配合使用。训练时所使用的 GPU 为 NVIDIA GeForce RTX 4090。模型参数如表 x 所示。

表1    模型参数
| 参数 | 参数意义| 数值
|:-:|:-:|:-:|
|hidden_size|BERT模型和LSTM的隐藏层大小|768
|num_labels|分类任务的标签数量|3
|dropout|Dropout层的丢弃率|0.1
|epsilon|对抗训练中扰动的大小|1e-5
|lr|AdamW优化器的学习率|5e-5
|num_epochs|训练的总轮数|3
|criterion|交叉熵损失函数|

<br>

### 5.4 对比实验
为了验证提出的模型在金融领域情感分析上的效果，本节对以下模型进行了对比实验。<br>

（1）BiLSTM : BiLSTM 是该领域的基线模型，是在LSTM(文献引用)的基础上进行改进和扩展的。<br>
在本模型中，我们采用了双向长短期记忆网络（BiLSTM）以增强文本分类的能力。BiLSTM层配置为64个单元，通过其双向结构，模型能有效学习文本数据的前向和后向依赖关系，这对处理序列数据至关重要。输出层采用Dense层，包含3个神经元（对应三个分类输出），使用softmax激活函数生成每个类别的预测概率。<br>
模型使用sparse_categorical_crossentropy作为损失函数，adam优化器进行参数优化，训练周期设为5次，批处理大小为32，同时使用20%的训练数据作为验证集以避免过拟合。这种配置使得模型在处理整个文本序列时能够从多个方向综合信息，提高对文本意义的理解深度，并准确地进行情感分类。<br>
![Local Image](图片\BiLSTM.png "Local Image Title")<br><br>

（2）BERT_CNN：在 BERT 模型下游引入CNN 提取词级特征。<br>
在本模型中，我们开发了一个结合BERT和卷积神经网络（CNN）的模型，称为BertCNN，用以提升文本分类的准确性和效率。通过使用预训练的BERT模型作为基础来提取文本的深层语义特征，并在此基础上通过一维卷积层（Conv1D）进一步提取关键的局部特征。该卷积层配备256个输出通道，卷积核大小为3，用于捕捉紧邻词汇间的特征关系。随后的最大池化层用于降维并提取最显著的特征，而Dropout层的引入则是为了减少过拟合，增强模型的泛化能力。模型的输出通过一个全连接层实现，该层包含与类别数量相对应的神经元，并使用softmax函数来预测各类别的概率。<br>
在训练过程中，模型采用sparse_categorical_crossentropy作为损失函数，利用Adam优化器进行参数优化，学习率设置为2e-5。整个训练过程中，模型经过三个训练周期，使用20%的训练数据作为验证集以避免过拟合。这种方法确保了模型在处理文本数据时能从多角度综合信息，从而在文本分类任务中达到更高的精度和效率。<br>

![Local Image](图片\BertCNN.png "Local Image Title")<br><br>

（3）BERT_wwm：文献[x] 等针对金融领域文本，基于 BERT 提出全词覆盖与特征增强的预训练模型，提高了金融文本情感分类的精度。<br>
在本模型中，我们采用了基于BERT的金融领域全词覆盖和特征增强预处理模型，专门针对金融文本的情感分析。此模型整合了全词覆盖（Whole Word Masking）策略和命名实体及词性标注的特征增强，有效提升了在金融领域文本中情感分类的精度。全词覆盖策略通过在训练过程中如果一个词的一部分被遮盖，整个词都将被遮盖，这样做能更准确地捕捉到词语的语义关联性。<br>
![Local Image](图片\BertWMM1.png "Local Image Title")<br>

特征增强部分通过词性标注和命名实体识别，将这些额外的语义信息融入预训练中，进一步丰富模型对文本的理解。这些特征通过Transformer的自注意力机制加以整合，提高了模型对金融特定元素如专业术语的敏感度，增强了模型对金融文本中细微情感差异的捕捉能力。<br>
![Local Image](图片\BertWMM2.png "Local Image Title")<br>

综合这些策略，BERT_wwm模型不仅在理解金融领域文本的复杂性上有所增强，也在实际应用中展示了较高的情感分类准确率，有效支持金融决策过程中的情感分析需求。<br>

（4）Fin⁃BERT：针对金融领域的NLP任务提出的预训练模型，可以更好地捕获语言知识和语义信息。<br>
（5）Our_Model：小组提出的模型。

表x展示了各个模型在数据集上的实验结果。可以看出，该文提出的模型在 Precision , Recall 以及 F1-score 上均优于其他模型。

对比实验
| Model | Precision| F1-score| Recall
|:-:|:-:|:-:|:-:|
|BiLSTM|74.90%|74.71%|74.95%
|BERT-CNN|75.22%|75.11%|75.15%
|BERT-wwm|7.92%|12.36%|28.14%
|FinBERT|78.62%|77.55%|78.45%
|Our Model|85.65%|85.65%|85.77%

<br>

![Local Image](图片\对比实验.png "Local Image Title")<br>


首先，与BiLSTM模型相比，我们提出的模型在精确度、召回率和F1值方面均有显著提高。具体来看，精确度从74.90%提升到85.65%，召回率从74.95%提升到85.77%，而F1值提高了近11百分点，从74.71%提高到85.65%。这一显著的改进主要得益于预训练模型提供的上下文嵌入的增强，这有助于模型更好地理解和处理金融领域的复杂语义。<br>
其次，与BERT-CNN和BERT-wwm相比，我们的模型在三个性能指标上均显示出较大幅度的提升。特别是与BERT-wwm相比，精确度从7.92%提升到85.65%，召回率从28.14%提升到85.77%，而F1值从12.36%提升到85.65%。这种显著的提升归因于FinBERT的预训练过程中包括大量金融专业语料的使用，使得模型在金融领域的任务处理上更为精准和有效。<br>
相比于FinBERT模型，我们的模型在每个评估指标上均显示出了约8百分点左右的提升。这不仅是因为模型能够从金融语料中提取更关键的文本深层情感信息，而且通过在嵌入层加入扰动，增强了模型对新数据的泛化能力和对噪声的鲁棒性。<br>
这些结果强调了在设计深度学习模型时考虑特定领域的语料预训练的重要性，以及进一步通过对抗训练增强模型鲁棒性的有效性。通过这种方式，我们的模型不仅在标准的性能指标上有所提升，更重要的是在实际应用中表现出更好的稳定性和可靠性。<br>


### 5.5 消融实验
为了考察模型中各个模块的有效性，设置了模型中不同结构的消融实验（见图x和图x） , 模型具体细节如下：FinBERT：金融领域的预训练模型；FinBERT_RCNN：预训练模型下游引入RCNN模型提取关键信息；FinBERT_对抗训练：预训练模型引入对抗训练；Our_Model：该文提出的模型。<br>
本节进行了消融实验，用来分析各模块的性能，结果记录在表x。通过消融实验发现模型的每个模块在提高性能方面都起着关键作用。

消融实验
| Model | Precision| F1-score| Recall|
|:-:|:-:|:-:|:-:|
|FindBERT-RCNN|84.64%|84.57%|84.54%|
|FindBERT-Attack|80.92%|79.36%|80.25%|
|FinBERT|78.62%|77.55%|78.45%|
|Our Model|86.65%|86.12%|86.51%|

<br>

![Local Image](图片\消融实验.png "Local Image Title")<br>



首先，FinBERT–RCNN模型在处理后的金融文本数据中展现了卓越的性能。通过采用FinBERT作为语言模型来处理上下文联系和语义信息，并结合RCNN来提取关键信息进行情感分类，模型在所有三个主要性能指标上均实现了显著提升。具体来看，精确度从FinBERT的78.62%提升到84.64%，召回率从78.45%提升到84.54%，而F1分数也从77.55%提升到84.57%，显示了RCNN模块在捕捉情感分类中关键特征方面的有效性。
其次，将对抗训练技术引入到FinBERT模型中，形成了FindBERT-Attack模型。此技术增强了模型对抗线性扰动攻击的能力，进一步提升了模型的鲁棒性和泛化性。相较于未经过对抗训练的FinBERT模型，FindBERT-Attack模型在精确度上从78.62%略微提升到80.92%，召回率从78.45%提升到80.25%，F1分数也从77.55%提升到79.36%。虽然提升幅度不如RCNN模型那般显著，这表明对抗训练在提升模型鲁棒性方面的作用更为微妙，但仍然有效。
最后，通过结合FinBERT的语义特征处理和RCNN的关键信息提取，并在模型中使用损失函数的梯度创建扰动，我们开发了Our Model。这一模型不仅保持了高水平的精确度和召回率，分别达到了86.65%和86.51%，而且在F1分数上也达到了86.12%，这一切都证明了模型设计的高效性和优越性。相比于原始的FinBERT模型，Our Model在精确度、召回率和F1分数上均有超过8百分点的全面提升，充分展现了整合多种技术后模型性能的显著增强。<br>

之后，我们小组又对Our Model进行了模型优化，特别是引入额外的卷积层和对抗训练策略，新模型（NEW_Model）在金融文本情感分析任务上表现出了显著的性能提升。
|   Model   | Precision | F1-score | Recall |
| :-------: | :-------: | :------: | :----: |
| NEW_Model |  92.17%   |  91.83%  | 92.04% |

精确度从原有模型的86.65%提高到92.17%，F1分数从86.12%提高到91.83%，召回率也从86.51%提升至92.04%。这些结果不仅显示了额外卷积层在深入提取文本特征方面的有效性，也突显了对抗训练在增强模型鲁棒性方面的重要作用。整体上，NEW_Model的表现超越了原始FinBERT模型，在所有主要性能指标上均实现了超过5百分点的提升，有效证明了结合深层特征学习与鲁棒性增强技术的设计策略的优越性。<br>


## 6 相关工作
### 6.1 存在的局限性和潜在的改进方向
1. 语境敏感性和语言的歧义性：
尽管FinBERT和RCNN模型改进了情感分析，但它们可能仍然难以处理金融语言固有的歧义性和特定语境下的含义。
改进方向： 实施更复杂的语境感知训练策略和更深入的语义分析可能有所帮助。采用根据文本周围语境变化的动态词嵌入技术，可以为金融术语提供更细致的解释。
2. 适应金融语言快速变化的能力：
金融语言由于监管变化、市场转移和新金融产品的出现而迅速演变。静态模型可能无法迅速适应这些变化。
改进方向： 持续学习框架能够实时或几乎实时地更新模型的理解，随着新数据的可用性增强适应性。
3. 对标记数据的依赖：
这两种方法仍然显著依赖于标记数据集进行训练，这在金融等专业领域既昂贵又耗时。
改进方向： 增加使用无监督或半监督学习方法可以减少对标记数据的依赖。采用自我训练或师生学习模型，其中模型迭代标记未标记数据并重新训练自己，可能是有益的。
4. 模型复杂性和效率：
像BERT这样的模型在训练和推理时需要大量的计算资源，这在时间敏感的金融环境中可能是不切实际的。
改进方向： 通过剪枝、量化和知识蒸馏优化模型架构，可以在不显著损失性能的情况下减少模型大小和计算需求。
5. 跨不同金融语境的泛化能力：
模型性能可能在不同类型的金融文本（如新闻与报告）之间显著不同。
改进方向： 开发针对不同类型金融文件的专门子模型，或引入元学习方法，其中模型学习如何适应各种金融语境，可能会提高泛化能力。<br>


## 7 未来展望
1. 整合到实时分析系统：
将这些模型实施在实时金融新闻和数据分析系统中，可能为市场情绪提供即时见解，帮助交易员和分析师做出更快的决策。
1. 增强特征工程：
探索更复杂的特征工程技术，能够捕捉金融语言的更高层次语义和句法特征，可能导致更健壮的模型。
1. 跨语言和跨域适应性：
扩展模型以理解多种语言并适应全球不同的金融市场，可能显著增加它们的实用性。
通过解决这些限制并探索所建议的改进，金融情感分析模型的下一代可能会实现更高的准确性、更好的泛化能力和更快的处理时间，使其更适合实际的金融应用。

## 参考文献
从原论文的参考文献里找一点出来。

## 附录
### 分工
详细描述每位团队成员的具体分工。

### 项目进度
展示项目的进度计划和实际完成情况。