# 汇报演讲稿

> 仅作为参考

- 第一页【标题】

​	【最开始的部分省略，比如开场白、成员介绍】本组的大作业研究方向是金融文本情感分析模型。

- 第二页【目录】

​	将从以下几个部分讲述，研究背景、问题定义、模型应用、结果展示以及总结和Q&A

- 第三页【研究背景】

​	首先是研究背景

- 第四页【研究背景详情】

  - 什么是情感分析
    - 在讨论什么是金融文本情感分析之前，需要先搞清楚什么是情感分析。情感分析一句话概括可以是“从书面语言中提取人的情绪或观点”。情感分析的目的是识别和提取文本材料中的主观信息。它主要用于了解人们在某个主题、产品或服务上的情绪倾向，通常分类为正面、负面或中性。
    - 情感分析可以应用在很多领域，比如企业对于市场的研究（可以帮助企业理解消费者对市场趋势的反应，以及他们对竞争对手产品的看法)、客户服务（自动识别客户查询中的情绪，帮助改善客户支持服务，并快速响应负面反馈）等。

  - 为什么要研究金融文本情感分析
    - 金融文本包含投资者的情绪及公众对相关事件的态度。 近年来，自然语言处理已广泛应用于金融领域，对金融文本数据进行情感分析可以得到丰富的投资价值和监管参考价值。 
    - 金融领域的文本数据包含对相关事件的情绪，对金融文本进行情感分析有助于理解投资者的态度，并影响投资决策和市场走势 。 
    - 每天都会有大量的词汇和信息出现，手动分析这些语言非常困难，需要自动化的方法来处理

- 第五页【问题定义】

​	接下来是本次研究的问题定义

- 第六页【问题定义详情】

  - 在选择和构建模型之前，需要清楚我们要做什么样的模型、解决什么问题，在训练过程中需要关注哪些进程和变化
  - 首先是选择哪种情感分析任务
    - 情感分析任务有多种分类
      - 二分类情感分析：将情感分为正面或负面。例如，分析一条推文是正面评价还是负面评价。
      - 多分类情感分析：除了正面和负面，还可能包括中性或其他更细分的情绪类别，如愤怒、快乐、悲伤等。
      - 方面级情感分析：不仅识别文本的情感倾向，还指出情感针对的具体方面或属性，例如在产品评论中识别对“电池寿命”或“屏幕质量”的情感表达。
      - 预测下一个词汇通常是语言模型的任务，如BERT或GPT。这些模型通过预测句子中下一个词的方式训练，从而学习词汇之间的关系和语境含义。

  - 然后是应该选择哪种应用模型的方法
    - 基于预训练模型的微调：如使用BERT进行微调，通过微调来适应特定的情感识别任务。
    - 特征提取：使用预训练的语言模型来提取文本特征，然后这些特征被用作训练情感分类器的输入。

  - 还有几个问题比如
    - 短句通常信息密度大，语境依赖性强，选择能够精确处理这些特性的模型可以提高情感分类的准确性和效率。我们需要探索与其他模型相比，选择什么样的模型在短句分类的方面表现更好？
    - 参数的调整对于模型的收敛速度和最终性能都有显著影响，使用的模型涉及到的参数都是如何改变训练结果的？
    - 如果没有适当的策略来保持之前学习的知识，模型可能会完全遗忘之前任务的知识。使用的模型能否减缓这种情况的出现？

- 第七页【问题定义详情】

  - 针对前面提出的问题，具体我们要研究的问题以及难点，确定选择模型的理由

    - 金融文本情感分析的难点在于
      - 金融文本有专门的语言和词汇，有时候有比较模糊的表达，不适用于一般的语料库
      - 现有模型易受到对抗样本的干扰导致模型结果出错
      - 神经网络，需要大量的标记数据和标记资金文本片段，需要大量专业知识

    - 选择预训练语言模型的理由是
      - 传统的方法难以提取到文本更深层次的情感特征
      - 在特定的语料库上进一步训练，其词嵌入包含了更多文本信息

    - 训练模型的核心思想
      - 在很大的语料库上训练模型
      - 在特定领域的未标记语料库上进一步预训练语言模型的能力

- 第八页【模型应用】

​	接下来是具体使用的模型介绍

- 第九页【数据集】
  - 本次训练使用的数据集是Sentiment Analysis for Financial News
  - 包含了从零售投资者角度来看的财经新闻标题的情绪，从图中可以看到数据集的内容包含两列，"Sentiment" 和 "News Headline"。情感可以是负面、中性或正面。我们划分80%（3876条）作为训练集，20%（970条）作为测试集
- 第十页【模型概念图】
  - 如图所示，本次项目当中引入了一种新的文本分析模型，FinBERT-RCNN-ATTACK，结合了FinBERT预训练模型和循环卷积神经网络（RCNN）。FinBERT模型利用大规模的金融数据进行预训练，在处理金融相关任务时表现出更好的适应性。
  - 它通过嵌入捕获文本的语义特征，为分析提供支持。另一方面，RCNN通过其结构优化了上下文信息的捕获，能够有效提取文本中的关键特征。
  - 引入了对抗性训练策略。通过使用损失函数的梯度来生成扰动，这些扰动被添加到文本嵌入中，随后模型在这些经过扰动的对抗样本上进行训练，实验预期是显著提升模型对抗新型攻击的能力。
- 第11页【finbert模块】
  - 如图所示，为了高效地从金融文本中提取语义特征，首先使用FinBERT预训练模型进行文本的嵌入处理，包括Token Embeddings、Segment Embeddings和Position Embeddings。![image-20240626231633335](C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240626231633335.png)
- 第12页【RCNN模块】
  - 虽然FinBERT模型能够有效处理文本的上下文和语义信息，但在关键信息提取方面存在局限性。仅依靠FinBERT提取的特征进行情感分类可能导致分类性能未充分发挥。
  - 结合FinBERT提取的语义特征和其他神经网络模型的特性可以有效提升整体的分类精度。模型引入了RCNN来强化特征提取过程。RCNN通过将传统卷积神经网络中的卷积层替换为具有递归结构的循环卷积层，建立了一个深度前馈网络。
  - 如图所示，卷积层能够分别从左到右及从右到左学习每个单词，从而捕捉字符及其上下文的全面信息。这些信息被输入到池化层，在池化层中通过max-pooling操作选取文本中最具代表性的关键特征。之后，特征通过全连接层进行处理，并最终通过softmax函数进行情感分类。这种方式结合了FinBERT和RCNN的模型不仅优化了特征的语义深度，一定程度上可以帮助模型提高情感分类任务的整体效果。

- 第13页【对抗训练】
  - 为了提高模型在现实世界应用中的可靠性，在文本表示模型生成的词向量中引入了对抗性扰动。这些扰动是在模型的输入数据中故意引入的微小变化，通常是为了欺骗模型使其产生错误的输出。

- 第14页【模型参数】
  - （这一块我个人认为阐述一下怎么找到这些值的）

- 第15页【结果展示】
- 第16页【对比实验】
  - 我们将自己的模型和以下几个模型进行了对比
  - BiLSTM 是该领域的基线模型，在LSTM的基础上进行改进和扩展。模型采用BiLSTM 以增强文本分类的能力。
  - BiLSTM层配置为64个单元，通过其双向结构，模型能有效学习文本数据的前向和后向依赖关系
  - 在 BERT 模型下游引入CNN 提取词级特征,，使用预训练的BERT模型作为基础来提取文本的深层语义特征，并在此基础上通过一维卷积层 Conv1D 进一步提取关键的局部特征。最大池化层用于降维并提取最显著的特征，而 Dropout层 的引入则是为了减少过拟合，增强模型的泛化能力
  - 采用基于BERT的金融领域全词覆盖和特征增强预处理模型，整合了全词覆盖 Whole WordMasking 策略和命名实体及词性标注的特征增强。全词覆盖策略通过在训练过程中如果一个词的一部分被遮盖，整个词都将被遮盖，这样做能更准确地捕捉到词语的语义关联性。
- 第17页【折线图】
  - 与BiLSTM模型相比：我们提出的模型在精确度、召回率和F1值方面均有显著提高主要得益于预训练模型提供的上下文嵌入的增强
  - 与BERT-CNN和BERT-wwm相比：我们的模型在三个性能指标上均显示出较大幅度的提升，归因于FinBERT的预训练过程中包括大量金融专业语料的使用，使得模型在金融领域的任务处理上更为精准和有效。
  - 与FinBERT模型相比：我们的模型在每个评估指标上均显示出了约8百分点左右的提升。这不仅是因为模型能够从金融语料中提取更关键的文本深层情感信息，而且通过在嵌入层加入扰动，增强了模型对新数据的泛化能力。
  - 这些结果强调了在设计深度学习模型时考虑特定领域的语料预训练的重要性，以及进一步通过对抗训练增强模型的有效性。
- 第18页【消融实验】
  - 为了考察模型中各个模块的有效性，设置了模型中不同结构的消融实验
  - 从实验结果 可以看出：
    - FinBERT–RCNN模型在处理后的金融文本数据中展现了卓越的性能。通过采用FinBERT作为语言模型来处理上下文联系和语义信息，并结合RCNN来提取关键信息进行情感分类，模型在所有三个主要性能指标上均实现了显著提升。
    - 将对抗训练技术引入到FinBERT模型中，形成了 FindBERT-Attack 模型。此技术增强了模型对抗线性扰动攻击的能力
    - 结合FinBERT的语义特征处理和RCNN的关键信息提取，并在模型中使用损失函数的梯度创建扰动，我们开发了Our Model。这一模型不仅保持了高水平的精确度和召回率，分别达到了86.65%和86.51%，而且在F1分数上也达到了86.12%，这一切都证明了模型设计的高效性和优越性。相比于原始的FinBERT模型，Our Model在精确度、召回率和F1分数上均有超过8百分点的全面提升，充分展现了整合多种技术后模型性能的显著增强。
- 第19页【持续优化】
  - 引入额外的卷积层和对抗训练策略，新模型（NEW_Model）在金融文本情感分析任务上表现出显著的性能提升
  - 结果显示额外卷积层在深入提取文本特征方面的有效性，也突显了对抗训练在增强模型方面的重要作用。
  - 整体上，NEW_Model的表现超越了原始FinBERT模型，在所有主要性能指标上均实现了超过5百分点的提升，有效证明了结合深层特征学习与鲁棒性增强技术的设计策略的优越性。
- 第20页【总结】
  - 本项目在金融文本情感分析领域通过改进FinBERT模型，显著提升了分析的准确性和效率。
  - FinBERT模型的优势在于其专门针对金融领域的语言特性进行了优化，这使得它在理解和解析金融文本中的情感变化方面表现出色。
  - 探讨了不同的训练周期和模型配置对最终结果的影响，通过多次实验，结合RCNN架构和对抗训练技术，找到最佳参数组合，也在不断筛选模型的过程中更清晰的了解了不同模型的优势和劣势，使得模型在保持高效的同时，也达到了较高的准确率，使得模型可以完成一些特定的任务。

- 第21页【Q&A】