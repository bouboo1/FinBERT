# 华东师范大学数据科学与工程学院课程设计报告

| 课程名称：社会计算                          | 组长： | 唐小卉 |
| ------------------------------------------- | ------ | ------ |
| 指导教师：赵明昊 树杨                       | 组员： | 王溢阳 |
| 小组名称：汪汪队                            |        | 杨茜雅 |
| 上机实践名称：基于FinBERT的金融文本情感分析 |        | 仲韦萱 |

## 摘要



```mermaid
graph LR
A[项目启动] --> B[选择FinBERT模型]
B --> C[数据集构建]
C --> D[模型训练]
D --> E[结果分析]
E --> F[优化策略提出]
F --> G[报告撰写]
G --> H[项目总结]
```

​	本项目在金融文本情感分析领域迈出了重要一步，通过采用FinBERT模型，我们初步解决了传统模型在处理专业金融语言时的局限性，显著提升了分析的准确性和效率。FinBERT模型的优势在于其专门针对金融领域的语言特性进行了优化，这使得它在理解和解析金融文本中的情感变化方面表现出色。

​	在数据集构建阶段，我们选择Kaggle上的金融新闻情感分析数据集，该数据集包含了丰富的情感标签，为模型的训练提供了坚实的基础。通过对这些数据的深入分析，我们发现FinBERT模型在区分不同情感类别时表现出了极高的准确性，尤其是在处理那些微妙的情感变化时，模型展现出了其独特的优势。

​	在模型训练过程中，我们不仅关注了模型的性能，还对训练参数进行了细致的调整。我们探讨了不同的训练周期和模型配置对最终结果的影响，通过多次实验，结合RCNN架构和对抗训练技术，找到最佳的参数组合，也在不断筛选模型的过程中更清晰的了解了不同模型的优势和劣势，使得模型在保持高效的同时，也达到了较高的准确率，使得模型可以完成一些特定的任务。

​	结果分析阶段，详细记录了模型的表现，并通过图表和模型结构图直观地展示了模型的运行过程和内部结构。这些详细的记录不仅有助于我们理解模型的运行机制，也为后续的优化工作提供了依据。

​	在优化策略的提出中，考虑多种可能性，包括集成学习方法的应用和引入更高效的计算硬件。这些策略的提出基于对当前模型性能的深入分析，旨在进一步提升模型的分析效率和准确性。

​	本次项目报告的内容总结了项目的整个过程，包括技术方案的实施、实验结果的分析以及优化方向的探讨。详细描述了本次项目当中小组所做的工作内容，如何从选择研究方向，到设计和初步构建模型，以及模型的优化和得出最终结果的经历，也丰富了我们查找阅读文献以及运用模型的能力。

​	综上所述，本项目不仅成功地应用了FinBERT模型于金融文本情感分析，还为该领域的进一步研究提供了宝贵的经验和数据支持。我们相信，随着技术的不断进步和优化，FinBERT模型也会在金融文本分析领域发挥更大的作用，希望能够为金融行业的决策提供更为精确和高效的支持。

**关键词：金融文本 情感分析 FinBERT模型 集成学习方法 对抗训练 RCNN**









## 研究背景

​	FinBERT 模型专注于金融领域的情感分析，这是因为金融语言具有高度专业性，且相关的标记数据相对稀缺。尽管传统的情感分析模型在通用文本上表现良好，但在处理充满专业术语的金融文本时常常力不从心。随着金融文本量的日益增长，人工分析变得不切实际，这增加了对高效自动化分析工具的需求。FinBERT通过预训练的BERT模型，并在金融特定数据上进行微调，有效提升了对金融情感的分析准确性。
​	基于FinBERT的初步实验成功，小组提出了将循环卷积神经网络（RCNN）与对抗训练相结合的集成学习模型——FinBERT-RCNN。RCNN结合了循环神经网络(RNN)和卷积神经网络(CNN)的优势，优化了文本数据的深层次语义特征提取。通过引入对抗训练，保持对序列或图像数据的高效处理能力，结合了两种技术的优势，以应对特定的挑战或任务。




## 研究意义
​	本次研究通过创新地结合RCNN架构和对抗训练技术，显著优化了金融领域的情感分析工具。这种方法不仅提高了情感分析的精度，还增强了模型对金融市场情绪波动的适应性和敏感性。FinBERT-RCNN的开发是否能在一定程度上帮助金融情感分析向更高精度和复杂情境适应性的进步，是否能够利用混合神经网络模型处理特定领域问题还需要市场的实际应用来给予验证。此外，对抗训练的引入为模型提供了额外的稳定性，帮助其在实际金融应用中更为可靠。

​	本次研究为金融情感分析领域带来了新的研究方向和实际应用的可能性，希望能够帮助准确地预测市场对金融新闻的反应，为金融决策提供科学依据。



## 问题描述

- 在金融领域进行情感分析是一项具有挑战性的任务
  - 金融文本中使用了大量的专业术语和特有的专业领域的语言表达，使得通用的情感分析模型难以有效适应这样特定场景下的任务。
  - 缺乏大量标注数据，使得训练精确的情感分析模型变得困难，因为标注金融文本片段需要耗费高昂的专业成本，并且相关开源资料也非常稀少。

​	针对以上这些任务中会遇到的问题，《FinBERT: Financial Sentiment Analysis with Pre-trained Language Models》一文提出的FinBERT模型通过使用预训练的语言模型来捕捉文本的上下文语义信息，显著提高了模型在金融文本情感分析任务中的表现。

- 尽管FinBERT模型已在金融情感分析任务中取得显著成绩，仍存在一些不足之处：
  - FinBERT模型虽能有效捕捉上下文语义信息，但在提取文本中的关键信息方面仍有待加强。
  - 现有模型在抵御对抗性攻击方面的鲁棒性不足，容易受到微小扰动的影响，从而导致分类结果的不准确

​	基于这些问题，我们在FinBERT模型的基础上提出FinBERT-RCNN-ATTACK模型，旨在通过结合RCNN结构提高关键信息的提取能力，并引入对抗训练来增强模型的抗干扰性。
​	本研究的主要目标是验证通过进一步预训练和微调预训练语言模型，能否显著提高金融领域情感分析的准确性。我们的实验将集中在如何通过增强模型的关键信息提取能力，初步解决FinBERT在金融文本情感分析中遇到的挑战。



## 数据集介绍

> 数据集名称：Sentiment Analysis for Financial News

​	选取公开的英文数据集对提出的模型和其他现有模型进行实验，划分80%（3876条）作为训练集，20%（970条）作为测试集。该数据集包含从零售投资者视角出发的金融新闻标题的情感标注，用于研究和分析金融新闻对市场参与者情绪的影响，尤其关注新闻标题所蕴含的情绪倾向。通过对新闻标题的情感分析，可以帮助金融分析师和投资者更好地理解市场动态，预测市场趋势。
​	数据集包括两个字段：“情感”（Sentiment）和“新闻标题”（News Headline）。情感分类包括负面（negative）、中性（neutral）和正面（positive），这使得研究者可以直接利用这些数据进行情感分析，探索不同新闻标题背后的情感色彩。

![image-20240619172931267](C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240619172931267.png)

## 模型设计

​	本次项目当中引入了一种新的文本分析模型，FinBERT-RCNN-ATTACK，结合了FinBERT预训练模型和循环卷积神经网络（RCNN）。FinBERT模型利用大规模的金融数据进行预训练，在处理金融相关任务时表现出更好的适应性。它通过嵌入捕获文本的语义特征，为分析提供支持。另一方面，RCNN通过其结构优化了上下文信息的捕获，能够有效提取文本中的关键特征。
​	引入了对抗性训练策略。通过使用损失函数的梯度来生成扰动，这些扰动被添加到文本嵌入中，随后模型在这些经过扰动的对抗样本上进行训练，实验预期是显著提升模型对抗新型攻击的能力。
​	模型的结构如下图所示，有效地融合了FinBERT嵌入和RCNN技术，并通过对抗训练进一步增强了模型性能。

![图1模型结构](C:\Users\86133\Desktop\FinBERT-main\static\图1模型结构.png)



 ### 4.1 FinBERT 模块
​	为了高效地从金融文本中提取语义特征，首先使用FinBERT预训练模型进行文本的嵌入处理，包括Token Embeddings、Segment Embeddings和Position Embeddings。



![图2嵌入](C:\Users\86133\Desktop\FinBERT-main\static\图2嵌入.png)

- **Token Embeddings**：将文本中的词转换为固定维度的向量，这是基本的语义信息编码。
- **Segment Embeddings**：这些嵌入帮助模型区分同一句子对中两个不同句子，增强模型处理边界的能力。
- **Position Embeddings**：FinBERT能够识别输入序列中词的位置，有助于模型理解文本的顺序结构。

​	这三种向量的组合通过加和形式作为模型的输入，综合保留原始文本的综合信息和情感倾向，为后续的任务提供支持。具体来说，组合后的向量
$$
[ E_{\text{word}} = E_{\text{tok}} + E_{\text{seg}} + E_{\text{pos}} ]
$$
被用作输入，进一步通过多层Transformer结构进行特征提取，得到序列中各位置的特征向量 
$$
[ T_1, T_2, \ldots, T_n ]
$$
​	这样的结构不仅提高了特征提取的精确性，还增强了模型对复杂金融语境的适应能力。

### 4.2 RCNN 模块

​	情感分类的挑战主要在于从文本中提取具有决定性的信息。虽然FinBERT模型能够有效处理文本的上下文和语义信息，但在关键信息提取方面存在局限性。仅依靠FinBERT提取的特征进行情感分类可能导致分类性能未充分发挥。因此，结合FinBERT提取的语义特征和其他神经网络模型的特性可以有效提升整体的分类精度。

​	在这个部分，模型引入了RCNN来强化特征提取过程。RCNN通过将传统卷积神经网络中的卷积层替换为具有递归结构的循环卷积层，建立了一个深度前馈网络。

![图3循环卷积层结构](C:\Users\86133\Desktop\FinBERT-main\static\图3循环卷积层结构.png)循环	如图所示，卷积层能够分别从左到右及从右到左学习每个单词，从而捕捉字符及其上下文的全面信息。这些信息被输入到池化层，在池化层中通过max-pooling操作选取文本中最具代表性的关键特征。之后，特征通过全连接层进行处理，并最终通过softmax函数进行情感分类。这种方式结合了FinBERT和RCNN的模型不仅优化了特征的语义深度，一定程度上可以帮助模型提高情感分类任务的整体效果。


### 4.3 对抗训练
​	为了提高模型在现实世界应用中的可靠性和效果，本研究在文本表示模型生成的词向量中引入了对抗性扰动。这些扰动是在模型的输入数据中故意引入的微小变化，通常是为了欺骗模型使其产生错误的输出。对抗训练可以看作是一种强化学习的形式，它迫使模型在面对极端或非典型输入时依然能够作出准确预测。这有助于模型在面对多样化的数据集时展现出更好的泛化能力。

根据文献提出的方法，对抗扰动是通过使用损失函数的梯度来计算得到的，具体公式如下：

$$
[ r_{\text{adv}} = \arg \min \log p(y | x + r; \theta) ]
[ \text{subject to} \ \|r\| \leq \epsilon ]
$$
公式参数解释如下：

- $$
   p(y \mid x; \theta)
  $$

  在给定输入` x `和模型参数 `θ`的情况下，预测标签 `y`的概率

- `r`是加在输入上的扰动，且此扰动在足够小的范围内被严格限制。目标是寻找能够最大化模型预测误差的最优扰动
- 对抗性扰动被添加到输入嵌入中，以在嵌入空间中构造新的对抗性文本实例

## 实验评估


### 5.1 评估指标
实验使用精确率( Precision) 、召回率 ( Recall) 和F1 分数(F1-Score)作为衡量模型分类性能的标准，计算公式如下

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

$$
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$

- TP( True Positive) 表示被正确预测的正例 
- FP (False Positive)表示被错误预测的正例
- FN (False Negative) 表示被错误预测的反例 

### 5.2 实验环境
- pytorch 2.2.1
- CUDA 11.8
- GPU: NVIDA GeForce RTX4090

### 5.3 模型参数

| 参数 | 含义 | 数值|
|:-:|:-:|:-:|
|hidden_size|BERT模型和LSTM的隐藏层大小|768|
|num_labels|分类任务的标签数量|3|
|dropout|Dropout层的丢弃率|0.1|
|epsilon|对抗训练中扰动的大小|1e-5|
|lr|AdamW优化器的学习率|5e-5|
|num_epochs|训练的总轮数|3|
|criterion|交叉熵损失函数||

### 5.4 对比实验
- **BiLSTM** 
  -  BiLSTM 是该领域的基线模型，在LSTM(文献引用)的基础上进行改进和扩展。模型采用`BiLSTM`以增强文本分类的能力。
  - BiLSTM层配置为64个单元，通过其双向结构，模型能有效学习文本数据的前向和后向依赖关系，这对处理序列数据至关重要。
  - 输出层采用Dense层，包含3个神经元（对应三个分类输出），使用`softmax激活函数`生成每个类别的预测概率。
  - 使用`sparse_categorical_crossentropy`作为损失函数，`adam优化器`进行参数优化，训练周期设为5次，批处理大小为32，同时使用20%的训练数据作为验证集以避免过拟合。
  - 这种配置使得模型在处理整个文本序列时能够从多个方向综合信息，提高对文本意义的理解深度，并准确地进行情感分类。![BiLSTM](C:\Users\86133\Desktop\FinBERT-main\static\BiLSTM.png)

- **BERT_CNN**：
  - 在 BERT 模型下游引入CNN 提取词级特征,，使用预训练的BERT模型作为基础来提取文本的深层语义特征，并在此基础上通过一维卷积层`Conv1D`进一步提取关键的局部特征。
  - 该卷积层配备256个输出通道，卷积核大小为3，用于捕捉紧邻词汇间的特征关系
  - 最大池化层用于降维并提取最显著的特征，而`Dropout层`的引入则是为了减少过拟合，增强模型的泛化能力。
  - 模型的输出通过一个全连接层实现，该层包含与类别数量相对应的神经元，并使用`softmax函数`来预测各类别的概率。
  - 模型采用`sparse_categorical_crossentropy`作为损失函数，利用`Adam优化器`进行参数优化，学习率设置为2e-5。整个训练过程中，模型经过三个训练周期，使用20%的训练数据作为验证集以避免过拟合。这种方法确保了模型在处理文本数据时能从多角度综合信息，从而在文本分类任务中达到更高的精度和效率。![BertCNN](C:\Users\86133\Desktop\FinBERT-main\static\BertCNN.png)

- **BERT_wwm**

  - 采用基于BERT的金融领域全词覆盖和特征增强预处理模型，整合了全词覆盖`Whole Word Masking`策略和命名实体及词性标注的特征增强
  - 全词覆盖策略通过在训练过程中如果一个词的一部分被遮盖，整个词都将被遮盖，这样做能更准确地捕捉到词语的语义关联性。
    ![BertWMM1](C:\Users\86133\Desktop\FinBERT-main\static\BertWMM1.png)

  - 特征增强部分通过词性标注和命名实体识别，将这些额外的语义信息融入预训练中，进一步丰富模型对文本的理解。这些特征通过Transformer的自注意力机制加以整合，提高了模型对金融特定元素如专业术语的敏感度，增强了模型对金融文本中细微情感差异的捕捉能力。![BertWMM2](C:\Users\86133\Desktop\FinBERT-main\static\BertWMM2.png)

  - 综合这些策略，BERT_wwm模型不仅在理解金融领域文本的复杂性上有所增强，也在实际应用中展示了较高的情感分类准确率，有效支持金融决策过程中的情感分析需求。

- Fin⁃BERT：针对金融领域的NLP任务提出的预训练模型，可以更好地捕获语言知识和语义信息
- Our_Model：小组提出的模型。

下表展示了各个模型在数据集上的实验结果。可以看出，该文提出的模型在 Precision , Recall 以及 F1-score 上均优于其他模型。

| Model | Precision| F1-score| Recall
|:-:|:-:|:-:|:-:|
|BiLSTM|74.90%|74.71%|74.95%
|BERT-CNN|75.22%|75.11%|75.15%
|BERT-wwm|7.92%|12.36%|28.14%
|FinBERT|78.62%|77.55%|78.45%
|Our Model|85.65%|85.65%|85.77%

![对比实验](C:\Users\86133\Desktop\FinBERT-main\static\对比实验.png)

- **与BiLSTM模型相比**：我们提出的模型在精确度、召回率和F1值方面均有显著提高。具体来看，**精确度从74.90%提升到85.65%，召回率从74.95%提升到85.77%**，**而F1值提高了近11百分点，从74.71%提高到85.65%**。这一显著的改进主要得益于预训练模型提供的上下文嵌入的增强，这有助于模型更好地理解和处理金融领域的复杂语义。
- **与BERT-CNN和BERT-wwm相比**：我们的模型在三个性能指标上均显示出较大幅度的提升。特别是与BERT-wwm相比，**精确度从7.92%提升到85.65%，召回率从28.14%提升到85.77%，而F1值从12.36%提升到85.65%**。这种显著的提升归因于FinBERT的预训练过程中包括大量金融专业语料的使用，使得模型在金融领域的任务处理上更为精准和有效。
- **与FinBERT模型相比**：我们的模型在**每个评估指标上均显示出了约8百分点左右的提升**。这不仅是因为模型能够从金融语料中提取更关键的文本深层情感信息，而且通过在嵌入层加入扰动，增强了模型对新数据的泛化能力。

​	这些结果强调了在设计深度学习模型时考虑特定领域的语料预训练的重要性，以及进一步通过对抗训练增强模型的有效性。通过这种方式，我们的模型不仅在标准的性能指标上有所提升，更重要的是在实际应用中表现出更好的稳定性和可靠性。

### 5.5 消融实验

​	为了考察模型中各个模块的有效性，设置了模型中不同结构的消融实验

- 模型具体细节如下
  - FinBERT：金融领域的预训练模型
  - FinBERT_RCNN：预训练模型下游引入RCNN模型提取关键信息
  - FinBERT_对抗训练：预训练模型引入对抗训练
  - Our_Model：该文提出的模型。本节进行了消融实验

消融实验模型效果如下表所示：
| Model | Precision| F1-score| Recall|
|:-:|:-:|:-:|:-:|
|FindBERT-RCNN|84.64%|84.57%|84.54%|
|FindBERT-Attack|80.92%|79.36%|80.25%|
|FinBERT|78.62%|77.55%|78.45%|
|Our Model|86.65%|86.12%|86.51%|

![消融实验](C:\Users\86133\Desktop\FinBERT-main\static\消融实验.png)

从实验结果 可以看出：

- FinBERT–RCNN模型在处理后的金融文本数据中展现了卓越的性能。通过采用FinBERT作为语言模型来处理上下文联系和语义信息，并结合RCNN来提取关键信息进行情感分类，模型在所有三个主要性能指标上均实现了显著提升。
- **精确度从FinBERT的78.62%提升到84.64%，召回率从78.45%提升到84.54%，而F1分数也从77.55%提升到84.57%**，显示了RCNN模块在捕捉情感分类中关键特征方面的有效性。
- 将对抗训练技术引入到FinBERT模型中，形成了`FindBERT-Attack`模型。此技术增强了模型对抗线性扰动攻击的能力，相较于未经过对抗训练的FinBERT模型，**FindBERT-Attack模型在精确度上从78.62%略微提升到80.92%，召回率从78.45%提升到80.25%，F1分数也从77.55%提升到79.36%**。虽然提升幅度不如RCNN模型那般显著，这表明对抗训练在提升模型鲁棒性方面的作用更为微妙，但仍然有效。
- 结合FinBERT的语义特征处理和RCNN的关键信息提取，并在模型中使用损失函数的梯度创建扰动，我们开发了Our Model。这一模型不仅**保持了高水平的精确度和召回率，分别达到了86.65%和86.51%，而且在F1分数上也达到了86.12%**，这一切都证明了模型设计的高效性和优越性。相比于原始的FinBERT模型，Our Model在精确度、召回率和F1分数上均有超过8百分点的全面提升，充分展现了整合多种技术后模型性能的显著增强。

### 5.6 持续优化

引入额外的卷积层和对抗训练策略，新模型（NEW_Model）在金融文本情感分析任务上表现出显著的性能提升。

|   Model   | Precision | F1-score | Recall |
| :-------: | :-------: | :------: | :----: |
| NEW_Model |  92.17%   |  91.83%  | 92.04% |

​	**精确度从原有模型的86.65%提高到92.17%，F1分数从86.12%提高到91.83%，召回率也从86.51%提升至92.04%**。这些结果不仅显示了额外卷积层在深入提取文本特征方面的有效性，也突显了对抗训练在增强模型鲁棒性方面的重要作用。整体上，NEW_Model的表现超越了原始FinBERT模型，在所有主要性能指标上均实现了超过5百分点的提升，有效证明了结合深层特征学习与鲁棒性增强技术的设计策略的优越性。


## 相关工作
### 6.1 存在的局限性和潜在的改进方向
- **语境敏感性和语言的歧义性**：
  尽管FinBERT和RCNN模型改进了情感分析，但它们可能仍然难以处理金融语言固有的歧义性和特定语境下的含义。
  **改进方向**： 实施更复杂的语境感知训练策略和更深入的语义分析可能有所帮助。采用根据文本周围语境变化的动态词嵌入技术，可以为金融术语提供更细致的解释。

- **适应金融语言快速变化的能力：**
  金融语言由于监管变化、市场转移和新金融产品的出现而迅速演变。静态模型可能无法迅速适应这些变化。
  **改进方向**： 持续学习框架能够实时或几乎实时地更新模型的理解，随着新数据的可用性增强适应性。

- **对标记数据的依赖**：
  这两种方法仍然显著依赖于标记数据集进行训练，这在金融等专业领域既昂贵又耗时。
  **改进方向：** 增加使用无监督或半监督学习方法可以减少对标记数据的依赖。采用自我训练或师生学习模型，其中模型迭代标记未标记数据并重新训练自己，可能是有益的。

- **模型复杂性和效率：**
  像BERT这样的模型在训练和推理时需要大量的计算资源，这在时间敏感的金融环境中可能是不切实际的。
  **改进方向**： 通过剪枝、量化和知识蒸馏优化模型架构，可以在不显著损失性能的情况下减少模型大小和计算需求。

- **跨不同金融语境的泛化能力**：
  模型性能可能在不同类型的金融文本（如新闻与报告）之间显著不同。
  **改进方向：** 开发针对不同类型金融文件的专门子模型，或引入元学习方法，其中模型学习如何适应各种金融语境，可能会提高泛化能力。


### 6.2 未来展望
- **整合到实时分析系统**
       将这些模型实施在实时金融新闻和数据分析系统中，可能为市场情绪提供即时见解，帮助交易员和分析师做出更快的决策。

- **增强特征工程**
       探索更复杂的特征工程技术，能够捕捉金融语言的更高层次语义和句法特征，可能导致更健壮的模型。

- **跨语言和跨域适应性**
       扩展模型以理解多种语言并适应全球不同的金融市场，可能显著增加它们的实用性。
  通过解决这些限制并探索所建议的改进，金融情感分析模型的下一代可能会实现更高的准确性、更好的泛化能力和更快的处理时间，使其更适合实际的金融应用。

## 参考文献
- Araci, D. (2019). *FinBERT: Financial Sentiment Analysis with Pre-trained Language Models*. Unpublished master's thesis, University of Amsterdam, Amsterdam, Netherlands.
- Neel Kant, Raul Puri, Nikolai Yakovenko, and Bryan Catanzaro. 2018. Practical Text Classification With Large Pre-Trained Language Models. (2018).
- Chi Sun, Xipeng Qiu, Yige Xu, and Xuanjing Huang. 2019. How to Fine-TuneBERT for Text Classification? (2019). arXiv:1905.05583
- Lei Zhang, Shuai Wang, and Bing Liu. 2018. Deep learning for sentiment analysis: A survey. *Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery*8, 4 (mar 2018), e1253.

## 附录
### 分工
- 人力分配：文书2、模型2
  - 文书：杨茜雅、王溢阳
    - 阅读文献、项目报告、PPT、演讲稿等
  - 模型：唐小卉、仲韦萱
    - 模型搭建、训练、模型图等

### 项目进度
- 确定大作业项目方向【已完成】
- 查找阅读文献【已完成】
- 初步完成模型选择【已完成】
- 查找数据集【已完成】
- 确定详细分工以及具体研究方向和方法【已完成】
- 搭建模型和训练【已完成】
- 优化参数、提高准确率【已完成】
- 绘制模型图、记录训练结果【已完成】
- 项目报告【已完成】
- PPT设计【已完成】
- 演讲汇报【待完成：6.29】